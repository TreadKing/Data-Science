{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "In this homework assignment, you will implement a univariate feature selection method. \n",
    "\n",
    "You will be given a toy dataset called 'Car Evaluation Data Set' (see: http://archive.ics.uci.edu/ml/datasets/Car+Evaluation for details).\n",
    "You are not required to, but advised to test your code with the toy dataset, or any other dataset that contains categorical variables.\n",
    "\n",
    "The given dataset contains six descriptive features and a target variable. Each of those are ordinal scale, categorical variables. The name of the target feature is 'evaluation'. \n",
    "\n",
    "Note here that you are expected to write your own code, so DO NOT COPY AND PASTE CODE OR USE LIBRARY FUNCTIONS. The goal of the homework is not to see if you can call library functions but to have you practice with the impurity measures and feature selection techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1728 entries, 0 to 1727\nData columns (total 7 columns):\nbuying        1728 non-null object\nmaint         1728 non-null object\ndoors         1728 non-null object\npersons       1728 non-null object\nlug_boot      1728 non-null object\nsafety        1728 non-null object\nevaluation    1728 non-null object\ndtypes: object(7)\nmemory usage: 94.6+ KB\n"
    }
   ],
   "source": [
    "edf = pd.read_csv('careval.csv')\n",
    "# edf.head()\n",
    "edf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will create a method called IUFS (impurity-based univariate feature selection), which will select the most informative features with a univariate feature selection schema. This feature selection method will take the dataset, name of the target variable, number of features to be selected (k) and the measure of impurity as an input, and will output the names of k best features based on the information gain. You are expected to implement information gain, entropy and Gini index functions. Note here that this will be a univariate selection, which means that you need to test the features individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "entropy: \n2.0\nverify results with scipy entropy function: \n2.0\n"
    }
   ],
   "source": [
    "# entropy (H)\n",
    "\n",
    "def entropy2(feature, dataset):\n",
    "    \"\"\"Calculates the entropy of a feature in a given dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        entropy for the feature in the dataset\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "    num_items = len(dataset[feature])\n",
    "    #make the feature into a numpy array for easier manipulations\n",
    "    entropy_array = dataset[feature].to_numpy()\n",
    "    #print(t_array)\n",
    "    #count the ocurreance of each different value in the data\n",
    "    values, counts = np.unique(entropy_array, return_counts=True)\n",
    "    #print(values)\n",
    "    #print(counts)\n",
    "    #calculate the probability of each value\n",
    "    prob = counts / num_items\n",
    "    #print(prob)\n",
    "\n",
    "    sum = 0\n",
    "\n",
    "    #calculate entropy\n",
    "    for val in prob:\n",
    "        sum -= val * np.log2(val)\n",
    "    return sum\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print('entropy: ')\n",
    "print(entropy2('buying', edf))\n",
    "\n",
    "#verify results with scipy entropy function\n",
    "print('verify results with scipy entropy function: ')\n",
    "t_array = edf['buying'].to_numpy()\n",
    "values, counts = np.unique(t_array, return_counts=True)\n",
    "print(entropy(counts, base = 2))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Gini Index:\n0.75\n"
    }
   ],
   "source": [
    "# gini index (Gini)\n",
    "\n",
    "def gini(feature, dataset):\n",
    "    \"\"\"Calculates the gini index of a feature in a given dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        gini index for the feature in the dataset\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "    gini_array = dataset[feature].to_numpy()\n",
    "    num_items = gini_array.size\n",
    "    #print(num_items)\n",
    "    values, counts = np.unique(gini_array, return_counts=True)\n",
    "    #print(values)\n",
    "    #print(counts)\n",
    "    prob = counts / num_items\n",
    "\n",
    "    #calculater gini index\n",
    "\n",
    "    sum = 1\n",
    "\n",
    "    for val in prob:\n",
    "        sum -= (val**2)\n",
    "\n",
    "    return sum\n",
    "\n",
    "print('Gini Index:')\n",
    "print(gini('buying', edf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The information gain using entropy: \n0.09644896916961382\nThe information gain using gini: \n0.014286077889231807\n"
    }
   ],
   "source": [
    "# information gain (IG)\n",
    "\n",
    "def IG(feature, target, dataset, measure):\n",
    "    \"\"\"Calculates the information gain of a feature for a given target variable and a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    measure: str ('entropy' or 'gini')\n",
    "        measure of impurity to be used\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        information gain for the feature in the dataset for a given target variable\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "    array = dataset[feature].to_numpy()\n",
    "    num_items = array.size\n",
    "    values, counts = np.unique(array, return_counts=True)\n",
    "    prob = counts / num_items\n",
    "    grouped = dataset.groupby(dataset[feature])\n",
    "    groups = []\n",
    "    for item in values:\n",
    "        groups.append(grouped.get_group(item))\n",
    "\n",
    "    if measure.lower() == 'gini':\n",
    "        gini_val = gini(target, dataset)\n",
    "        for i in range(len(groups)):\n",
    "            gini_val -= (prob[i] * gini(target,groups[i]))\n",
    "        return gini_val\n",
    "\n",
    "\n",
    "    if measure.lower() == 'entropy':\n",
    "        entropy_val = entropy2(target, dataset)\n",
    "        for i in range(len(groups)):\n",
    "            entropy_val -= (prob[i] * entropy2(target,groups[i]))\n",
    "        return entropy_val\n",
    "\n",
    "\n",
    "print('The information gain using entropy: ')\n",
    "print(IG('buying','evaluation', edf, 'entropy'))\n",
    "print('The information gain using gini: ')\n",
    "print(IG('buying','evaluation', edf, 'gini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Features with the most infomration gain with gini\n['safety', 'persons']\nFeatures with the most information gain with entropy\n['safety', 'persons']\n"
    }
   ],
   "source": [
    "def IUFS(target, dataset, k, measure='entropy'):\n",
    "    \"\"\"Finds k most informative features in the given dataset based on the target variable\n",
    "        using information gain with the selected measure.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    k: int\n",
    "        number of features to return, must be less than or equal to number of descriptive features in dataset.\n",
    "        in other words, 0 < k < len(dataset.columns).\n",
    "    measure: str, 'entropy' or 'gini'\n",
    "        measure of impurity\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        returns a list of k feature names, selected based on univariate selection schema\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "    col_list = dataset.columns\n",
    "\n",
    "    ig_list = []\n",
    "    val_list = []\n",
    "\n",
    "    \n",
    "    for i in range(len(col_list)-1):\n",
    "        #print(IG(col_list[i], target, dataset, measure))\n",
    "        ig_list.append([col_list[i],IG(col_list[i], target, dataset, measure)])\n",
    "        val_list.append(IG(col_list[i], target, dataset, measure))\n",
    "\n",
    "    d = {}\n",
    "    arr = np.array(val_list)\n",
    "    arr.sort()\n",
    "    for lst in ig_list:\n",
    "        d[lst[1]] = lst[0]\n",
    "\n",
    "    return_list = []\n",
    "    for i in range(k):\n",
    "        return_list.append(d[arr[-i-1]])\n",
    "\n",
    "    return(return_list)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('Features with the most infomration gain with gini')\n",
    "print(IUFS('evaluation', edf, 2, measure='gini'))\n",
    "\n",
    "print('Features with the most information gain with entropy')\n",
    "print(IUFS('evaluation', edf, 2, measure='entropy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "Improve the IUFS by including an option for gain ratio. Gain ratio is an alternative to information gain and can be used with either of the Gini index or entropy measures.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GR(feature, target, dataset, measure):\n",
    "    \"\"\"Calculates the gain ratio of a feature for a given target variable and a dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature: str\n",
    "        name of the feature\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    measure: str ('entropy' or 'gini')\n",
    "        measure of impurity to be used\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        gain ratio for the feature in the dataset for a given target variable\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "\n",
    "# GR('buying','evaluation', edf, 'gini') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IUFS2(target, dataset, k, measure='entropy', gain='IG'):\n",
    "    \"\"\"Finds k most informative features in the given dataset based on the target variable\n",
    "        using information gain with the selected measure.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    target: str\n",
    "        name of the target variable\n",
    "    dataset: pd.DataFrame\n",
    "        dataframe for the dataset\n",
    "    k: int\n",
    "        number of features to return, must be less than or equal to number of descriptive features in dataset.\n",
    "        in other words, 0 < k < len(dataset.columns).\n",
    "    measure: str, 'entropy' or 'gini'\n",
    "        measure of impurity\n",
    "    gain: str, 'IG' or 'GR'\n",
    "        feature selection metric ('IG' for information gain, 'GR' for gain ratio)\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        returns a list of k feature names, selected based on univariate selection schema\n",
    "    \"\"\"\n",
    "    ##your implementation goes here\n",
    "    pass\n",
    "\n",
    "# IUFS2('evaluation', edf, 2, measure='gini', gain='GR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}